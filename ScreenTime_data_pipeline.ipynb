{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jzheng23/colab/blob/main/ScreenTime_data_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook can perform the following operations in order:\n",
        "\n",
        "1. Import data from Firebase and Qualtrics directly with API\n",
        "2. Save the data frames as temporary csv files\n",
        "3. Open the temporary csv files and save them to google drive"
      ],
      "metadata": {
        "id": "vgvNYTT3RIl4"
      },
      "id": "vgvNYTT3RIl4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "G4pMs-nbRIYx"
      },
      "id": "G4pMs-nbRIYx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive and set up file path"
      ],
      "metadata": {
        "id": "IHGd2zfFRtjA"
      },
      "id": "IHGd2zfFRtjA"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3EbblXTRf6I",
        "outputId": "eb7c7b4f-4690-44ad-c938-274b764e1c74"
      },
      "id": "l3EbblXTRf6I",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Google Drive path, depending who is running the notebook"
      ],
      "metadata": {
        "id": "-egH6q8BtHV5"
      },
      "id": "-egH6q8BtHV5"
    },
    {
      "cell_type": "code",
      "source": [
        "#Jian\n",
        "google_drive_data_path = '/content/drive/MyDrive/Problematic smartphone usage/Ambient display/Data'\n",
        "google_drive_key_path = '/content/drive/MyDrive/Problematic smartphone usage/Ambient display/Key'"
      ],
      "metadata": {
        "id": "cdizntv5qCsp"
      },
      "id": "cdizntv5qCsp",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Subin\n",
        "google_drive_data_path = '/content/drive/MyDrive/UMD_research/Problematic_Smartphone_Usage'\n",
        "google_drive_key_path = '/content/drive/MyDrive/UMD_research/Problematic_Smartphone_Usage'"
      ],
      "metadata": {
        "id": "dAxjtUZqKMm7"
      },
      "id": "dAxjtUZqKMm7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Firebase database"
      ],
      "metadata": {
        "id": "Z-x7WGXf-Uuf"
      },
      "id": "Z-x7WGXf-Uuf"
    },
    {
      "cell_type": "code",
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zy1HrBmDnOJx"
      },
      "id": "zy1HrBmDnOJx",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't re-run this cell unless the kernel has been restarted\n",
        "cred = credentials.Certificate(google_drive_key_path+'/timer-42ad2-firebase-adminsdk-4r7oj-2c373565f2.json')\n",
        "firebase_admin.initialize_app(cred, {\n",
        "    'databaseURL': 'https://timer-42ad2-default-rtdb.firebaseio.com'\n",
        "})"
      ],
      "metadata": {
        "id": "gFVB47CUKTsr"
      },
      "id": "gFVB47CUKTsr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Unix timestamp to date/datetime in specified timezone\n",
        "def convert_unix_to_date(unix_timestamp, timezone='America/New_York', return_date=True):\n",
        "   \"\"\"\n",
        "\n",
        "   Parameters:\n",
        "       unix_timestamp: Unix timestamp in milliseconds\n",
        "       timezone: String of timezone (default 'America/New_York')\n",
        "       return_date: If True returns date only, if False returns datetime\n",
        "   \"\"\"\n",
        "   dt = pd.to_datetime(unix_timestamp, unit='ms', utc=True).tz_convert(timezone)\n",
        "   return dt.date() if return_date else dt"
      ],
      "metadata": {
        "id": "QQdQsFQSslsy"
      },
      "id": "QQdQsFQSslsy",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response data"
      ],
      "metadata": {
        "id": "EQ-a_Ljo7Wm_"
      },
      "id": "EQ-a_Ljo7Wm_"
    },
    {
      "cell_type": "code",
      "source": [
        "def process_responses(responses, pid, host, survey_id):\n",
        "    responses_data = []\n",
        "    response_dict = {\n",
        "        'pid': pid,\n",
        "        'host': host,\n",
        "        'surveyID': survey_id\n",
        "    }\n",
        "\n",
        "    if isinstance(responses, dict):\n",
        "        for question_id, answer in responses.items():\n",
        "            response_dict[f'q_{question_id}'] = answer\n",
        "    elif isinstance(responses, list):\n",
        "        for question_id, answer in enumerate(responses):\n",
        "            if answer is not None:\n",
        "                response_dict[f'q_{question_id}'] = answer\n",
        "\n",
        "    responses_data.append(response_dict)\n",
        "    return responses_data\n",
        "\n",
        "def get_timestamp(data):\n",
        "    if isinstance(data, dict):\n",
        "        return data.get('a') or data.get('timestamp')\n",
        "    return None\n",
        "\n",
        "def get_responses(data):\n",
        "    if isinstance(data, dict):\n",
        "        return data.get('b') or data.get('responses')\n",
        "    elif isinstance(data, list):\n",
        "        return data\n",
        "    return None\n",
        "\n",
        "def is_host_level(data):\n",
        "    \"\"\"Check if this dictionary represents a host level\"\"\"\n",
        "    if isinstance(data, dict):\n",
        "        # Check if any value contains 'responses' or 'timestamp' keys\n",
        "        for value in data.values():\n",
        "            if isinstance(value, dict):\n",
        "                if 'responses' in value or 'timestamp' in value:\n",
        "                    return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "aW10klzrCMe_"
      },
      "id": "aW10klzrCMe_",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def responses_to_csvs(meta_file, responses_file):\n",
        "    ref = db.reference('/responses')\n",
        "    data = ref.get()\n",
        "\n",
        "    meta_data = []\n",
        "    responses_data = []\n",
        "\n",
        "    for pid, pid_data in data.items():\n",
        "        pid = pid.lower()\n",
        "        if not pid_data:\n",
        "            continue\n",
        "\n",
        "        if isinstance(pid_data, list):\n",
        "            for survey_id, survey_data in enumerate(pid_data):\n",
        "                if survey_data:\n",
        "                    timestamp = get_timestamp(survey_data)\n",
        "\n",
        "                    meta_data.append({\n",
        "                        'pid': pid,\n",
        "                        'host': pd.NA,\n",
        "                        'surveyID': str(survey_id),\n",
        "                        'timestamp': timestamp\n",
        "                    })\n",
        "\n",
        "                    responses = get_responses(survey_data)\n",
        "                    if responses:\n",
        "                        responses_data.extend(process_responses(responses, pid, pd.NA, str(survey_id)))\n",
        "        else:\n",
        "            # Check each item under pid\n",
        "            for key1, value1 in pid_data.items():\n",
        "                if isinstance(value1, dict):\n",
        "                    if is_host_level(value1):\n",
        "                        # This is a host\n",
        "                        host = key1\n",
        "                        for survey_id, survey_data in value1.items():\n",
        "                            if isinstance(survey_data, dict):\n",
        "                                timestamp = get_timestamp(survey_data)\n",
        "\n",
        "                                meta_data.append({\n",
        "                                    'pid': pid,\n",
        "                                    'host': host,\n",
        "                                    'surveyID': survey_id,\n",
        "                                    'timestamp': timestamp\n",
        "                                })\n",
        "\n",
        "                                responses = get_responses(survey_data)\n",
        "                                if responses:\n",
        "                                    responses_data.extend(process_responses(responses, pid, host, survey_id))\n",
        "                    else:\n",
        "                        # This is a survey (no host)\n",
        "                        survey_id = key1\n",
        "                        survey_data = value1\n",
        "                        timestamp = get_timestamp(survey_data)\n",
        "\n",
        "                        meta_data.append({\n",
        "                            'pid': pid,\n",
        "                            'host': pd.NA,\n",
        "                            'surveyID': survey_id,\n",
        "                            'timestamp': timestamp\n",
        "                        })\n",
        "\n",
        "                        responses = get_responses(survey_data)\n",
        "                        if responses:\n",
        "                            responses_data.extend(process_responses(responses, pid, pd.NA, survey_id))\n",
        "\n",
        "    # Create and save metadata DataFrame\n",
        "    meta_df = pd.DataFrame(meta_data)\n",
        "    meta_df = meta_df[['pid', 'host', 'surveyID', 'timestamp']]  # ensure column order\n",
        "    meta_df.to_csv(meta_file, index=False)\n",
        "\n",
        "    # Create responses DataFrame in wide format\n",
        "    responses_df = pd.DataFrame(responses_data)\n",
        "\n",
        "    # Ensure the first columns are in the correct order\n",
        "    first_cols = ['pid', 'host', 'surveyID']\n",
        "\n",
        "    # Get question columns and sort them numerically\n",
        "    q_cols = [col for col in responses_df.columns if col.startswith('q_')]\n",
        "    q_cols.sort(key=lambda x: int(x.split('_')[1]))  # Sort by the number after 'q_'\n",
        "\n",
        "    # Combine columns in correct order\n",
        "    responses_df = responses_df[first_cols + q_cols]\n",
        "\n",
        "    responses_df.to_csv(responses_file, index=False)"
      ],
      "metadata": {
        "id": "gY-U1T6RHNFp"
      },
      "id": "gY-U1T6RHNFp",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "responses_to_csvs('survey_meta.csv', 'survey_responses.csv')\n",
        "\n",
        "survey_meta_data = pd.read_csv('/content/survey_meta.csv')\n",
        "print(\"The shape of the survey_meta_data is \" + str(survey_meta_data.shape))\n",
        "survey_meta_data.to_csv(google_drive_data_path + '/survey_meta.csv', index=False)\n",
        "survey_responses_data = pd.read_csv('/content/survey_responses.csv')\n",
        "print(\"The shape of the survey_responses_data is \" + str(survey_responses_data.shape))\n",
        "survey_responses_data.to_csv(google_drive_data_path + '/survey_responses.csv', index=False)"
      ],
      "metadata": {
        "id": "yTWJeIa2Bdoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2ab28d-f35f-4449-e087-ed390380e0ae"
      },
      "id": "yTWJeIa2Bdoi",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the survey_meta_data is (18, 4)\n",
            "The shape of the survey_responses_data is (18, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TODO* still cannot read the host\n",
        "\n",
        "In the real data there should always be a host"
      ],
      "metadata": {
        "id": "HLHOV_udHoPp"
      },
      "id": "HLHOV_udHoPp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This should work for the real data, not tested yet\n",
        "\n",
        "Select all the lines and use Ctrl + / to uncomment"
      ],
      "metadata": {
        "id": "BkMeOVklIPMB"
      },
      "id": "BkMeOVklIPMB"
    },
    {
      "cell_type": "code",
      "source": [
        "# def process_responses(responses, pid, host, survey_id):\n",
        "#     responses_data = []\n",
        "#     response_dict = {\n",
        "#         'pid': pid,\n",
        "#         'host': host,\n",
        "#         'surveyID': survey_id\n",
        "#     }\n",
        "\n",
        "#     if isinstance(responses, dict):\n",
        "#         for question_id, answer in responses.items():\n",
        "#             response_dict[f'q_{question_id}'] = answer\n",
        "#     elif isinstance(responses, list):\n",
        "#         for question_id, answer in enumerate(responses):\n",
        "#             if answer is not None:\n",
        "#                 response_dict[f'q_{question_id}'] = answer\n",
        "\n",
        "#     responses_data.append(response_dict)\n",
        "#     return responses_data\n",
        "\n",
        "# def get_timestamp(data):\n",
        "#     if isinstance(data, dict):\n",
        "#         return data.get('a') or data.get('timestamp')\n",
        "#     return None\n",
        "\n",
        "# def get_responses(data):\n",
        "#     if isinstance(data, dict):\n",
        "#         return data.get('b') or data.get('responses')\n",
        "#     elif isinstance(data, list):\n",
        "#         return data\n",
        "#     return None\n",
        "\n",
        "# def responses_to_csvs(meta_file, responses_file):\n",
        "#     ref = db.reference('/responses')\n",
        "#     data = ref.get()\n",
        "\n",
        "#     meta_data = []\n",
        "#     responses_data = []\n",
        "\n",
        "#     for pid, pid_data in data.items():\n",
        "#         if not pid_data:\n",
        "#             continue\n",
        "\n",
        "#         # Process each host under pid\n",
        "#         for host, host_data in pid_data.items():\n",
        "#             # Process each survey under host\n",
        "#             for survey_id, survey_data in host_data.items():\n",
        "#                 timestamp = get_timestamp(survey_data)\n",
        "\n",
        "#                 meta_data.append({\n",
        "#                     'pid': pid,\n",
        "#                     'host': host,\n",
        "#                     'surveyID': survey_id,\n",
        "#                     'timestamp': timestamp\n",
        "#                 })\n",
        "\n",
        "#                 responses = get_responses(survey_data)\n",
        "#                 if responses:\n",
        "#                     responses_data.extend(process_responses(responses, pid, host, survey_id))\n",
        "\n",
        "#     # Create and save metadata DataFrame\n",
        "#     meta_df = pd.DataFrame(meta_data)\n",
        "#     meta_df = meta_df[['pid', 'host', 'surveyID', 'timestamp']]  # ensure column order\n",
        "#     meta_df.to_csv(meta_file, index=False)\n",
        "\n",
        "#     # Create responses DataFrame in wide format\n",
        "#     responses_df = pd.DataFrame(responses_data)\n",
        "\n",
        "#     # Ensure the first columns are in the correct order\n",
        "#     first_cols = ['pid', 'host', 'surveyID']\n",
        "\n",
        "#     # Get question columns and sort them numerically\n",
        "#     q_cols = [col for col in responses_df.columns if col.startswith('q_')]\n",
        "#     q_cols.sort(key=lambda x: int(x.split('_')[1]))\n",
        "\n",
        "#     # Combine columns in correct order\n",
        "#     responses_df = responses_df[first_cols + q_cols]\n",
        "\n",
        "#     responses_df.to_csv(responses_file, index=False)"
      ],
      "metadata": {
        "id": "rpkligPVIOxd"
      },
      "id": "rpkligPVIOxd",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Screen events"
      ],
      "metadata": {
        "id": "BgIVGzJj7cqO"
      },
      "id": "BgIVGzJj7cqO"
    },
    {
      "cell_type": "code",
      "source": [
        "def firebase_to_csv_log_Screen (ref_path, output_file):\n",
        "    ref = db.reference(ref_path)\n",
        "    data = ref.get()\n",
        "    transformed_data = []\n",
        "\n",
        "    # dictionary structure\n",
        "    for pid, events in data.items():  # 'pid' = key\n",
        "        pid = pid.lower()\n",
        "        if isinstance(events, list):\n",
        "            for index, event in enumerate(events, start=0):  #event_label_start:1\n",
        "                if event is None:\n",
        "                    continue\n",
        "                if isinstance(event, dict):\n",
        "                    row = {'pid': pid,\n",
        "                        'eventLabel': index,\n",
        "                        'startTime': event.get('startTime'),\n",
        "                        'endTime': event.get('endTime')}\n",
        "                    transformed_data.append(row)\n",
        "\n",
        "    df = pd.DataFrame(transformed_data)\n",
        "    df = df[['pid', 'eventLabel', 'startTime', 'endTime']]\n",
        "    df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "u_U08auqLWlk"
      },
      "id": "u_U08auqLWlk",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv_log_Screen('/screen_events','screen_events.csv')\n",
        "screen_events_data = pd.read_csv('/content/screen_events.csv')\n",
        "print(\"The shape of the screen_events_data is \" + str(screen_events_data.shape))\n",
        "screen_events_data.to_csv(google_drive_data_path + '/screen_events.csv', index=False)"
      ],
      "metadata": {
        "id": "CLCIRK2H7qgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4562b1-7433-420e-c3c8-7aa0011f2160"
      },
      "id": "CLCIRK2H7qgu",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the screen_events_data is(1304, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting changes"
      ],
      "metadata": {
        "id": "gPZfk9lA7e8f"
      },
      "id": "gPZfk9lA7e8f"
    },
    {
      "cell_type": "code",
      "source": [
        "def firebase_to_csv_log_setting (ref_path, output_file):\n",
        "    ref = db.reference(ref_path)\n",
        "    data = ref.get()\n",
        "    transformed_data = []\n",
        "\n",
        "    # dictionary structure\n",
        "    for pid, changes in data.items():  # 'pid' = key\n",
        "        if isinstance(changes, list):\n",
        "            for index, change in enumerate(changes, start=0):  #event_label_start:1\n",
        "                if change is None:\n",
        "                    continue\n",
        "                if isinstance(change, dict):\n",
        "                    row = {'pid': pid,\n",
        "                        'eventLabel': index,\n",
        "                        'newValue' : change.get('newValue'),\n",
        "                        'setting': change.get('setting'),\n",
        "                        'timestamp': change.get('timestamp')}\n",
        "                    transformed_data.append(row)\n",
        "\n",
        "    df = pd.DataFrame(transformed_data)\n",
        "    df = df[['pid', 'newValue', 'setting', 'timestamp']]\n",
        "    df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "7wKmjI3kdlhZ"
      },
      "id": "7wKmjI3kdlhZ",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv_log_setting('/settings_change_logs','settings_change_logs.csv')\n",
        "settings_change_logs_data = pd.read_csv('/content/settings_change_logs.csv')\n",
        "print(\"The shape of the settings_change_logs_data is \" + str(settings_change_logs_data.shape))\n",
        "settings_change_logs_data.to_csv(google_drive_data_path + '/settings_change_logs.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4BKVzrla3cL",
        "outputId": "288bd72c-c85d-4fa7-d912-83819a0e2adf"
      },
      "id": "z4BKVzrla3cL",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the settings_change_logs_data is (21, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ringer"
      ],
      "metadata": {
        "id": "m4Meu_IQiuts"
      },
      "id": "m4Meu_IQiuts"
    },
    {
      "cell_type": "code",
      "source": [
        "def firebase_to_csv_log_mode(ref_path, output_file):\n",
        "    ref = db.reference(ref_path)\n",
        "    data = ref.get()\n",
        "    transformed_data = []\n",
        "\n",
        "    for pid, middle_levels in data.items():\n",
        "        pid = pid.lower()\n",
        "        for middle_key, sub_changes in middle_levels.items():\n",
        "            for index, event in enumerate(sub_changes):\n",
        "                if isinstance(event, dict):\n",
        "                    row = {'pid': pid,'host':middle_key,'label': str(index),\n",
        "                        'mode': event.get('mode'),\n",
        "                        'timestamp': event.get('timestamp')}\n",
        "                    transformed_data.append(row)\n",
        "\n",
        "    df = pd.DataFrame(transformed_data)\n",
        "    df = df[['pid', 'host', 'label', 'mode', 'timestamp']]\n",
        "    df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "NkA5rfhwv1Ga"
      },
      "id": "NkA5rfhwv1Ga",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv_log_mode('/ringer_mode_events','ringer_mode_events.csv')\n",
        "ringer_mode_events_data = pd.read_csv('/content/ringer_mode_events.csv')\n",
        "print(\"The shape of the ringer_mode_events_data is \" + str(ringer_mode_events_data.shape))\n",
        "ringer_mode_events_data.to_csv(google_drive_data_path + '/ringer_mode_events.csv', index=False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KbCPCVA6iud8"
      },
      "id": "KbCPCVA6iud8",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ringer_mode_events_data0['label'] = ringer_mode_events_data0.groupby('pid').cumcount() + 1\n",
        "# ringer_mode_events_data0"
      ],
      "metadata": {
        "id": "41RkSPqx75hm"
      },
      "id": "41RkSPqx75hm",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device info"
      ],
      "metadata": {
        "id": "2u0oTRRn5593"
      },
      "id": "2u0oTRRn5593"
    },
    {
      "cell_type": "code",
      "source": [
        "# this function works for device and timezone infor\n",
        "def firebase_to_csv(ref_path, output_file):\n",
        "    # Get reference to device_info\n",
        "    ref = db.reference(ref_path)\n",
        "    data = ref.get()\n",
        "\n",
        "    transformed_data = []\n",
        "\n",
        "    # Transform the nested structure\n",
        "    for pid, pid_data in data.items():\n",
        "        pid = pid.lower()\n",
        "\n",
        "        if isinstance(pid_data, str):\n",
        "            # Case where timezone is directly under pid\n",
        "            row = {\n",
        "                'pid': pid,\n",
        "                'host': pd.NA,  # or None\n",
        "                'timezone': pid_data\n",
        "            }\n",
        "            transformed_data.append(row)\n",
        "        else:\n",
        "            # Case where pid has host-timezone pairs\n",
        "            for host, timezone in pid_data.items():\n",
        "                row = {\n",
        "                    'pid': pid,\n",
        "                    'host': host,\n",
        "                    'timezone': timezone\n",
        "                }\n",
        "                transformed_data.append(row)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(transformed_data)\n",
        "\n",
        "    # Ensure pid and host are the first columns\n",
        "    cols = ['pid', 'host'] + [col for col in df.columns if col not in ['pid', 'host']]\n",
        "    df = df[cols]\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "TAhF2VZv5Zr1"
      },
      "id": "TAhF2VZv5Zr1",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv('/device_info','device_info.csv')\n",
        "device_data = pd.read_csv('/content/device_info.csv')\n",
        "print(\"The shape of the device_data0 is \" + str(device_data.shape))\n",
        "device_data.to_csv(google_drive_data_path + '/device_info.csv', index=False)"
      ],
      "metadata": {
        "id": "OmCRGkAJIVWR"
      },
      "id": "OmCRGkAJIVWR",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Timezone info"
      ],
      "metadata": {
        "id": "9c66xeLT7nfI"
      },
      "id": "9c66xeLT7nfI"
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv('/timezones','timezones.csv')\n",
        "timezones_data = pd.read_csv('/content/timezones.csv')\n",
        "print(\"The shape of the timezones_data is \" + str(timezones_data.shape))\n",
        "timezones_data.to_csv(google_drive_data_path + '/timezones_data.csv', index=False)"
      ],
      "metadata": {
        "id": "do7aFA789Lzw"
      },
      "id": "do7aFA789Lzw",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Counters"
      ],
      "metadata": {
        "id": "2vwb_EftYtPp"
      },
      "id": "2vwb_EftYtPp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't actually need top analyze the counter data"
      ],
      "metadata": {
        "id": "HrOus7dZ8BjX"
      },
      "id": "HrOus7dZ8BjX"
    },
    {
      "cell_type": "code",
      "source": [
        "# def firebase_to_csv_counters(ref_path, output_file):\n",
        "#     ref = db.reference(ref_path)\n",
        "#     data = ref.get()\n",
        "#     transformed_data = []\n",
        "#     for pid, value in data.items():\n",
        "#         pid = pid.lower()\n",
        "#         # Case 1: only numeric\n",
        "#         if isinstance(value, int):\n",
        "#             transformed_data.append({'pid': pid, 'screen_event_count': value})\n",
        "\n",
        "#         # Case 2: dictionary => selecting only value\n",
        "#         elif isinstance(value, dict):\n",
        "#             numeric_values = [v for v in value.values() if isinstance(v, int)]\n",
        "#             if numeric_values:\n",
        "#                 total = sum(numeric_values)\n",
        "#                 transformed_data.append({'pid': pid, 'screen_event_count': total})\n",
        "\n",
        "#     df = pd.DataFrame(transformed_data)\n",
        "#     df = df[['pid', 'screen_event_count']]\n",
        "#     df.to_csv(output_file, index=False)\n",
        "\n",
        "\n",
        "# firebase_to_csv_counters('/ringer_event_counters','ringer_event_counters.csv')\n",
        "# ringer_event_counters_data0 = pd.read_csv('/content/ringer_event_counters.csv')\n",
        "# print(ringer_event_counters_data0.head())\n",
        "\n",
        "# firebase_to_csv_counters('/screen_event_counters','screen_event_counters.csv')\n",
        "# screen_event_counters_data0 = pd.read_csv('/content/screen_event_counters.csv')\n",
        "# print(screen_event_counters_data0.head())\n",
        "\n",
        "# firebase_to_csv_counters('/settings_change_counters','settings_change_counters.csv')\n",
        "# settings_change_counters_data0 = pd.read_csv('/content/settings_change_counters.csv')\n",
        "# print(settings_change_counters_data0.head())"
      ],
      "metadata": {
        "id": "fk6_muXpjtZx"
      },
      "id": "fk6_muXpjtZx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qualtrics data"
      ],
      "metadata": {
        "id": "GXkpBVhZ-mUA"
      },
      "id": "GXkpBVhZ-mUA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sign-up survey"
      ],
      "metadata": {
        "id": "9wPrJCrVsmBq"
      },
      "id": "9wPrJCrVsmBq"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import json\n",
        "import time\n",
        "import io\n",
        "\n",
        "def get_qualtrics_data(api_token, survey_id):\n",
        "    # API configurations\n",
        "    base_url = f\"https://pdx1.qualtrics.com/API/v3/surveys/{survey_id}/export-responses\"\n",
        "    headers = {\n",
        "        \"X-API-TOKEN\": api_token,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    # Start export\n",
        "    export_payload = '{\"format\":\"csv\"}'\n",
        "    export_response = requests.post(base_url, data=export_payload, headers=headers)\n",
        "    export_progress_id = export_response.json()[\"result\"][\"progressId\"]\n",
        "\n",
        "    # Check export progress\n",
        "    while True:\n",
        "        progress_response = requests.get(\n",
        "            f\"{base_url}/{export_progress_id}\",\n",
        "            headers=headers\n",
        "        )\n",
        "        progress_status = progress_response.json()[\"result\"][\"status\"]\n",
        "\n",
        "        if progress_status == \"complete\":\n",
        "            file_id = progress_response.json()[\"result\"][\"fileId\"]\n",
        "            break\n",
        "        time.sleep(2)\n",
        "\n",
        "    # Download file\n",
        "    download_response = requests.get(\n",
        "        f\"{base_url}/{file_id}/file\",\n",
        "        headers=headers\n",
        "    )\n",
        "\n",
        "    # Extract zip file\n",
        "    with zipfile.ZipFile(io.BytesIO(download_response.content)) as zip_file:\n",
        "        return zip_file.read(zip_file.namelist()[0]).decode('utf-8')\n"
      ],
      "metadata": {
        "id": "KQJtch0aeAI_"
      },
      "id": "KQJtch0aeAI_",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sign_up_survey = \"SV_dgN8IwiCIfglbAq\"\n",
        "api_token = \"U5xGlZmJv76LsjIXvfwB7FS9RqrqwmMb3vva3pbD\""
      ],
      "metadata": {
        "id": "aRlntIsPfArY"
      },
      "id": "aRlntIsPfArY",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signup_survey_data = get_qualtrics_data(api_token, sign_up_survey)\n",
        "# Then save to CSV\n",
        "with open('signup_survey_data.csv', 'w') as f:\n",
        "    f.write(signup_survey_data)\n",
        "    f.close()\n",
        "\n",
        "signup_survey_data = pd.read_csv('signup_survey_data.csv')\n",
        "print(\"The shape of the signup_survey_data is \" + str(signup_survey_data.shape))\n",
        "signup_survey_data.to_csv(google_drive_data_path + '/signup_survey_data.csv', index=False)"
      ],
      "metadata": {
        "id": "xgrZdnIDZ4th"
      },
      "id": "xgrZdnIDZ4th",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consent form"
      ],
      "metadata": {
        "id": "vwgkHqxIspAw"
      },
      "id": "vwgkHqxIspAw"
    },
    {
      "cell_type": "code",
      "source": [
        "consert_form_survey = \"SV_1Y79vGshtWh9FPM\"\n",
        "consent_form_data = get_qualtrics_data(api_token, consert_form_survey)\n",
        "\n",
        "with open('consent_form_data.csv', 'w') as f:\n",
        "    f.write(consent_form_data)\n",
        "    f.close()\n",
        "\n",
        "consent_form_data = pd.read_csv('consent_form_data.csv')\n",
        "print(\"The shape of the consent_form_data is \" + str(consent_form_data.shape))\n",
        "consent_form_data.to_csv(google_drive_data_path + '/consent_form_data.csv', index=False)"
      ],
      "metadata": {
        "id": "B2CVTn7C9MNq"
      },
      "id": "B2CVTn7C9MNq",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "AU2TzoXMwogx"
      },
      "id": "AU2TzoXMwogx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unused code. Don't run this cell unless you know what you are doing."
      ],
      "metadata": {
        "id": "bYdA6E1Xwqvq"
      },
      "id": "bYdA6E1Xwqvq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Ringer mode changes, with mixed data structure. Hopefully we don't need this\n",
        "\n",
        "# def firebase_to_csv_log_mode(ref_path, output_file):\n",
        "#     ref = db.reference(ref_path)\n",
        "#     data = ref.get()\n",
        "#     transformed_data = []\n",
        "\n",
        "#     for pid, middle_levels in data.items():\n",
        "#         pid = pid.lower()\n",
        "#         for middle_key, sub_changes in middle_levels.items():\n",
        "#             # process: checking the structure of sub_data (dic or list)\n",
        "#             if isinstance(sub_changes, dict):\n",
        "#                 for sub_key, event in sub_changes.items():\n",
        "#                     if isinstance(event, dict):\n",
        "#                         row = {'pid': pid, 'host':middle_levels, 'label': sub_key,\n",
        "#                             'mode': event.get('mode'),\n",
        "#                             'timestamp': event.get('timestamp')}\n",
        "#                         transformed_data.append(row)\n",
        "#             elif isinstance(sub_changes, list):  # sub_changes -> list\n",
        "#                 for index, event in enumerate(sub_changes):\n",
        "#                     if isinstance(event, dict):\n",
        "#                         row = {'pid': pid,'label': str(index),\n",
        "#                             'mode': event.get('mode'),\n",
        "#                             'timestamp': event.get('timestamp')}\n",
        "#                         transformed_data.append(row)\n",
        "\n",
        "#     df = pd.DataFrame(transformed_data)\n",
        "#     df = df[['pid', 'label', 'mode', 'timestamp']]\n",
        "#     df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "oe5P18lm2kSi"
      },
      "execution_count": 61,
      "outputs": [],
      "id": "oe5P18lm2kSi"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45EImRPHw3uw"
      },
      "id": "45EImRPHw3uw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "UXresearch",
      "language": "python",
      "name": "umd"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gqdYWWAYD4fa",
        "IsRr8hvAki9Q"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}