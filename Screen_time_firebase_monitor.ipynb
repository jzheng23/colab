{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BgIVGzJj7cqO",
        "2u0oTRRn5593",
        "9c66xeLT7nfI",
        "b6xFu8KGeiBr",
        "gPZfk9lA7e8f",
        "m4Meu_IQiuts",
        "2vwb_EftYtPp",
        "yo3YdmPp0ZCb"
      ],
      "authorship_tag": "ABX9TyN7zDqM2s4+on9saOHgKQ13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jzheng23/colab/blob/main/Screen_time_firebase_monitor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides the codes to check the progress of each participant, including two main functions:\n",
        "1. Check the last update of screen events from each participant\n",
        "2. Generate a list of emails (to be copied), to whom we should send a reminder email"
      ],
      "metadata": {
        "id": "UN2spQWn-0hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "FxrxgTCQjNMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive and set up file path"
      ],
      "metadata": {
        "id": "QKn_oSCKjNMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55a1f14-b2f3-4bd9-d4b6-61e909a741eb",
        "id": "oqZx3uxIjNMU"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Google Drive path, depending who is running the notebook"
      ],
      "metadata": {
        "id": "gju8PTwCjNMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Jian\n",
        "google_drive_data_path = '/content/drive/MyDrive/Problematic smartphone usage/Ambient display/Data'\n",
        "google_drive_key_path = '/content/drive/MyDrive/Problematic smartphone usage/Ambient display/Key'"
      ],
      "metadata": {
        "id": "mlDqMP9njNMU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Subin\n",
        "# google_drive_data_path = '/content/drive/MyDrive/UMD_research/Problematic_Smartphone_Usage'\n",
        "# google_drive_key_path = '/content/drive/MyDrive/UMD_research/Problematic_Smartphone_Usage'"
      ],
      "metadata": {
        "id": "0Gv7pCnfjNMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime"
      ],
      "metadata": {
        "id": "sFP3YyHUJR1h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Unix timestamp to date/datetime in specified timezone\n",
        "def convert_unix_to_date(unix_timestamp, timezone='America/New_York', return_date=True):\n",
        "   \"\"\"\n",
        "\n",
        "   Parameters:\n",
        "       unix_timestamp: Unix timestamp in milliseconds\n",
        "       timezone: String of timezone (default 'America/New_York')\n",
        "       return_date: If True returns date only, if False returns datetime\n",
        "   \"\"\"\n",
        "   dt = pd.to_datetime(unix_timestamp, unit='ms', utc=True).tz_convert(timezone)\n",
        "   return dt.date() if return_date else dt"
      ],
      "metadata": {
        "id": "AHxiU4FrJhoB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Firebase database"
      ],
      "metadata": {
        "id": "Z-x7WGXf-Uuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up link"
      ],
      "metadata": {
        "id": "aIimX4uCjq-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zy1HrBmDnOJx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't re-run this cell unless the kernel has been restarted\n",
        "cred = credentials.Certificate(google_drive_key_path+'/timer-42ad2-firebase-adminsdk-4r7oj-2c373565f2.json')\n",
        "firebase_admin.initialize_app(cred, {\n",
        "    'databaseURL': 'https://timer-42ad2-default-rtdb.firebaseio.com'\n",
        "})"
      ],
      "metadata": {
        "id": "gFVB47CUKTsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1dd0ca-5308-478e-b33a-8f0c57f50c3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<firebase_admin.App at 0x79b663ad79a0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Unix timestamp to date/datetime in specified timezone\n",
        "def convert_unix_to_date(unix_timestamp, timezone='America/New_York', return_date=True):\n",
        "   \"\"\"\n",
        "\n",
        "   Parameters:\n",
        "       unix_timestamp: Unix timestamp in milliseconds\n",
        "       timezone: String of timezone (default 'America/New_York')\n",
        "       return_date: If True returns date only, if False returns datetime\n",
        "   \"\"\"\n",
        "   dt = pd.to_datetime(unix_timestamp, unit='ms', utc=True).tz_convert(timezone)\n",
        "   return dt.date() if return_date else dt"
      ],
      "metadata": {
        "id": "QQdQsFQSslsy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response data"
      ],
      "metadata": {
        "id": "EQ-a_Ljo7Wm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_responses(responses, pid, host, survey_id):\n",
        "    responses_data = []\n",
        "    response_dict = {\n",
        "        'pid': pid,\n",
        "        'host': host,\n",
        "        'surveyID': survey_id\n",
        "    }\n",
        "\n",
        "    if isinstance(responses, dict):\n",
        "        for question_id, answer in responses.items():\n",
        "            response_dict[f'q_{question_id}'] = answer\n",
        "    elif isinstance(responses, list):\n",
        "        for question_id, answer in enumerate(responses):\n",
        "            if answer is not None:\n",
        "                response_dict[f'q_{question_id}'] = answer\n",
        "\n",
        "    responses_data.append(response_dict)\n",
        "    return responses_data\n",
        "\n",
        "def get_timestamp(data):\n",
        "    if isinstance(data, dict):\n",
        "        return data.get('a') or data.get('timestamp')\n",
        "    return None\n",
        "\n",
        "def get_responses(data):\n",
        "    if isinstance(data, dict):\n",
        "        return data.get('b') or data.get('responses')\n",
        "    elif isinstance(data, list):\n",
        "        return data\n",
        "    return None\n",
        "\n",
        "def firebase_to_csv_log_Screen(ref_path, output_file):\n",
        "    ref = db.reference(ref_path)\n",
        "    data = ref.get()\n",
        "    transformed_data = []\n",
        "\n",
        "    for pid, pid_data in data.items():\n",
        "        pid = pid.lower()\n",
        "\n",
        "        # Process each host under the pid\n",
        "        for host, events in pid_data.items():\n",
        "            if isinstance(events, list):\n",
        "                for index, event in enumerate(events):\n",
        "                    if event is not None and isinstance(event, dict):\n",
        "                        row = {\n",
        "                            'pid': pid,\n",
        "                            'host': host,\n",
        "                            'eventLabel': index,\n",
        "                            'startTime': event.get('startTime'),\n",
        "                            'endTime': event.get('endTime')\n",
        "                        }\n",
        "                        transformed_data.append(row)\n",
        "\n",
        "    df = pd.DataFrame(transformed_data)\n",
        "    if len(transformed_data) > 0:\n",
        "        df = df[['pid', 'host', 'eventLabel', 'startTime', 'endTime']]\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "def responses_to_csvs(meta_file, responses_file):\n",
        "    ref = db.reference('/responses')\n",
        "    data = ref.get()\n",
        "\n",
        "    meta_data = []\n",
        "    responses_data = []\n",
        "\n",
        "    for pid, pid_data in data.items():\n",
        "        pid = pid.lower()\n",
        "\n",
        "        # Process each host under pid\n",
        "        for host, host_data in pid_data.items():\n",
        "            # If host_data is a list, enumerate through it\n",
        "            if isinstance(host_data, list):\n",
        "                for survey_id, survey_data in enumerate(host_data):\n",
        "                    if survey_data is not None:\n",
        "                        timestamp = get_timestamp(survey_data)\n",
        "                        if timestamp:\n",
        "                            meta_data.append({\n",
        "                                'pid': pid,\n",
        "                                'host': host,\n",
        "                                'surveyID': str(survey_id),\n",
        "                                'timestamp': timestamp\n",
        "                            })\n",
        "\n",
        "                            responses = get_responses(survey_data)\n",
        "                            if responses:\n",
        "                                responses_data.extend(process_responses(responses, pid, host, str(survey_id)))\n",
        "\n",
        "    # Create and save metadata DataFrame\n",
        "    meta_df = pd.DataFrame(meta_data)\n",
        "    if len(meta_data) > 0:\n",
        "        meta_df = meta_df[['pid', 'host', 'surveyID', 'timestamp']]\n",
        "    meta_df.to_csv(meta_file, index=False)\n",
        "\n",
        "    # Create responses DataFrame in wide format\n",
        "    responses_df = pd.DataFrame(responses_data)\n",
        "\n",
        "    if len(responses_data) > 0:\n",
        "        first_cols = ['pid', 'host', 'surveyID']\n",
        "        q_cols = [col for col in responses_df.columns if col.startswith('q_')]\n",
        "        q_cols.sort(key=lambda x: int(x.split('_')[1]))\n",
        "        responses_df = responses_df[first_cols + q_cols]\n",
        "\n",
        "    responses_df.to_csv(responses_file, index=False)"
      ],
      "metadata": {
        "id": "Q4q0ytetcZIu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses_to_csvs('survey_meta.csv', 'survey_responses.csv')\n",
        "survey_meta_data = pd.read_csv('/content/survey_meta.csv')\n",
        "print(\"The shape of the survey_meta_data is \" + str(survey_meta_data.shape))\n",
        "survey_meta_data.to_csv(google_drive_data_path + '/survey_meta.csv', index=False)\n",
        "survey_responses_data = pd.read_csv('/content/survey_responses.csv')\n",
        "print(\"The shape of the survey_responses_data is \" + str(survey_responses_data.shape))\n",
        "survey_responses_data.to_csv(google_drive_data_path + '/survey_responses.csv', index=False)"
      ],
      "metadata": {
        "id": "yTWJeIa2Bdoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbdabb7-5872-4263-a8ea-12239a6c673c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the survey_meta_data is (22, 4)\n",
            "The shape of the survey_responses_data is (22, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Screen events"
      ],
      "metadata": {
        "id": "BgIVGzJj7cqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def firebase_to_csv_log_Screen(ref_path, output_file):\n",
        "    ref = db.reference(ref_path)\n",
        "    data = ref.get()\n",
        "    transformed_data = []\n",
        "\n",
        "    # dictionary structure\n",
        "    for pid, pid_data in data.items():\n",
        "        pid = pid.lower()\n",
        "\n",
        "        # Skip if pid_data is not a dictionary (to handle old format entries)\n",
        "        if not isinstance(pid_data, dict):\n",
        "            continue\n",
        "\n",
        "        # Process each host under the pid\n",
        "        for host, events in pid_data.items():\n",
        "            if not isinstance(events, list):\n",
        "                continue\n",
        "\n",
        "            for index, event in enumerate(events, start=0):\n",
        "                if event is None:\n",
        "                    continue\n",
        "                if isinstance(event, dict):\n",
        "                    row = {\n",
        "                        'pid': pid,\n",
        "                        'host': host,\n",
        "                        'eventLabel': index,\n",
        "                        'startTime': event.get('startTime'),\n",
        "                        'endTime': event.get('endTime')\n",
        "                    }\n",
        "                    transformed_data.append(row)\n",
        "\n",
        "    df = pd.DataFrame(transformed_data)\n",
        "    if len(transformed_data) > 0:\n",
        "        df = df[['pid', 'host', 'eventLabel', 'startTime', 'endTime']]\n",
        "    df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "_j9kjFxsa6PV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv_log_Screen('/screen_events','screen_events.csv')\n",
        "screen_events_data = pd.read_csv('/content/screen_events.csv')\n",
        "print(\"The shape of the screen_events_data is \" + str(screen_events_data.shape))\n",
        "screen_events_data.to_csv(google_drive_data_path + '/screen_events.csv', index=False)"
      ],
      "metadata": {
        "id": "CLCIRK2H7qgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c6d89e-a4c7-41e9-859f-48734437f231"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the screen_events_data is (2182, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device info"
      ],
      "metadata": {
        "id": "2u0oTRRn5593"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function works for device and timezone infor\n",
        "def firebase_to_csv(ref_path, output_file):\n",
        "    # Get reference to device_info\n",
        "    ref = db.reference(ref_path)\n",
        "    data = ref.get()\n",
        "\n",
        "    transformed_data = []\n",
        "\n",
        "    # Transform the nested structure\n",
        "    for pid, pid_data in data.items():\n",
        "        pid = pid.lower()\n",
        "\n",
        "        if isinstance(pid_data, str):\n",
        "            # Case where timezone is directly under pid\n",
        "            row = {\n",
        "                'pid': pid,\n",
        "                'host': pd.NA,  # or None\n",
        "                'timezone': pid_data\n",
        "            }\n",
        "            transformed_data.append(row)\n",
        "        else:\n",
        "            # Case where pid has host-timezone pairs\n",
        "            for host, timezone in pid_data.items():\n",
        "                row = {\n",
        "                    'pid': pid,\n",
        "                    'host': host,\n",
        "                    'timezone': timezone\n",
        "                }\n",
        "                transformed_data.append(row)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(transformed_data)\n",
        "\n",
        "    # Ensure pid and host are the first columns\n",
        "    cols = ['pid', 'host'] + [col for col in df.columns if col not in ['pid', 'host']]\n",
        "    df = df[cols]\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "TAhF2VZv5Zr1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv('/device_info','device_info.csv')\n",
        "device_data = pd.read_csv('/content/device_info.csv')\n",
        "\n",
        "# First let's convert the string representation of dictionary to actual dictionary\n",
        "device_data0 = device_data.copy()\n",
        "device_data0['timezone'] = device_data0['timezone'].apply(eval)\n",
        "\n",
        "# Now extract each field into its own column\n",
        "device_data0['Base'] = device_data0['timezone'].apply(lambda x: x.get('Base'))\n",
        "device_data0['Brand'] = device_data0['timezone'].apply(lambda x: x.get('Brand'))\n",
        "device_data0['Model'] = device_data0['timezone'].apply(lambda x: x.get('Model'))\n",
        "\n",
        "# If you want to drop the original timezone column, you can use:\n",
        "device_data = device_data0.drop('timezone', axis=1)\n",
        "\n",
        "print(\"The shape of the device_data is \" + str(device_data.shape))\n",
        "device_data.to_csv(google_drive_data_path + '/device_info.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftq95Onxf92a",
        "outputId": "048818d8-5677-4e82-da2a-de858009ead9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the device_data is (23, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Timezone info"
      ],
      "metadata": {
        "id": "9c66xeLT7nfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv('/timezones','timezones.csv')\n",
        "timezones_data = pd.read_csv('/content/timezones.csv')\n",
        "print(\"The shape of the timezones_data is \" + str(timezones_data.shape))\n",
        "timezones_data.to_csv(google_drive_data_path + '/timezones.csv', index=False)"
      ],
      "metadata": {
        "id": "do7aFA789Lzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7f9a90-a675-46fa-de83-3d842ae09e5f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the timezones_data is (23, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User states"
      ],
      "metadata": {
        "id": "b6xFu8KGeiBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data was introduced in an update of the app, so it only exist in some of the participants' data."
      ],
      "metadata": {
        "id": "vKtFpijBem5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv('/user_states','user_states.csv')\n",
        "user_states = pd.read_csv('/content/user_states.csv')"
      ],
      "metadata": {
        "id": "RCUS3KHpehUq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First convert the string representation of dictionary to actual dictionary\n",
        "user_states['timezone'] = user_states['timezone'].apply(eval)\n",
        "\n",
        "# Extract each field into its own column\n",
        "user_states['day_count'] = user_states['timezone'].apply(lambda x: x.get('day_count'))\n",
        "user_states['survey1_completed'] = user_states['timezone'].apply(lambda x: x.get('survey1_completed'))\n",
        "user_states['survey2_completed'] = user_states['timezone'].apply(lambda x: x.get('survey2_completed'))\n",
        "user_states['survey3_completed'] = user_states['timezone'].apply(lambda x: x.get('survey3_completed'))\n",
        "user_states['survey4_completed'] = user_states['timezone'].apply(lambda x: x.get('survey4_completed'))\n",
        "user_states['tutorial_completed'] = user_states['timezone'].apply(lambda x: x.get('tutorial_completed'))\n",
        "\n",
        "# Drop the original timezone column\n",
        "user_states = user_states.drop('timezone', axis=1)\n",
        "\n",
        "# Display the result\n",
        "print(\"The shape of the user_states is \" + str(user_states.shape))\n",
        "user_states.to_csv(google_drive_data_path + '/user_states.csv', index=False)\n"
      ],
      "metadata": {
        "id": "wdOXILAAhPpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c30cfb9-6c69-4e2b-d660-1c468114ae7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the user_states is (20, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting changes"
      ],
      "metadata": {
        "id": "gPZfk9lA7e8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data of setting changes will come in the third week. Don't run this chuck of code early than that, it will return just error.\n",
        "\n"
      ],
      "metadata": {
        "id": "DX9eu2pneHqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def firebase_to_csv_log_setting (ref_path, output_file):\n",
        "    ref = db.reference(ref_path)\n",
        "    data = ref.get()\n",
        "    transformed_data = []\n",
        "\n",
        "    # dictionary structure\n",
        "    for pid, changes in data.items():  # 'pid' = key\n",
        "        if isinstance(changes, list):\n",
        "            for index, change in enumerate(changes, start=0):  #event_label_start:1\n",
        "                if change is None:\n",
        "                    continue\n",
        "                if isinstance(change, dict):\n",
        "                    row = {'pid': pid,\n",
        "                        'eventLabel': index,\n",
        "                        'newValue' : change.get('newValue'),\n",
        "                        'setting': change.get('setting'),\n",
        "                        'timestamp': change.get('timestamp')}\n",
        "                    transformed_data.append(row)\n",
        "\n",
        "    df = pd.DataFrame(transformed_data)\n",
        "    df = df[['pid', 'newValue', 'setting', 'timestamp']]\n",
        "    df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "7wKmjI3kdlhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv_log_setting('/settings_change_logs','settings_change_logs.csv')\n",
        "settings_change_logs_data = pd.read_csv('/content/settings_change_logs.csv')\n",
        "print(\"The shape of the settings_change_logs_data is \" + str(settings_change_logs_data.shape))\n",
        "settings_change_logs_data.to_csv(google_drive_data_path + '/settings_change_logs.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4BKVzrla3cL",
        "outputId": "288bd72c-c85d-4fa7-d912-83819a0e2adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the settings_change_logs_data is (21, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ringer"
      ],
      "metadata": {
        "id": "m4Meu_IQiuts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data of ringer changes will come in the third week. Don't run this chuck of code early than that, it will return just error."
      ],
      "metadata": {
        "id": "h3syiJYaeZ-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def firebase_to_csv_log_mode(ref_path, output_file):\n",
        "    ref = db.reference(ref_path)\n",
        "    data = ref.get()\n",
        "    transformed_data = []\n",
        "\n",
        "    for pid, middle_levels in data.items():\n",
        "        pid = pid.lower()\n",
        "        for middle_key, sub_changes in middle_levels.items():\n",
        "            for index, event in enumerate(sub_changes):\n",
        "                if isinstance(event, dict):\n",
        "                    row = {'pid': pid,'host':middle_key,'label': str(index),\n",
        "                        'mode': event.get('mode'),\n",
        "                        'timestamp': event.get('timestamp')}\n",
        "                    transformed_data.append(row)\n",
        "\n",
        "    df = pd.DataFrame(transformed_data)\n",
        "    df = df[['pid', 'host', 'label', 'mode', 'timestamp']]\n",
        "    df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "NkA5rfhwv1Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_to_csv_log_mode('/ringer_mode_events','ringer_mode_events.csv')\n",
        "ringer_mode_events_data = pd.read_csv('/content/ringer_mode_events.csv')\n",
        "print(\"The shape of the ringer_mode_events_data is \" + str(ringer_mode_events_data.shape))\n",
        "ringer_mode_events_data.to_csv(google_drive_data_path + '/ringer_mode_events.csv', index=False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KbCPCVA6iud8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Counters"
      ],
      "metadata": {
        "id": "2vwb_EftYtPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't actually need top analyze the counter data"
      ],
      "metadata": {
        "id": "HrOus7dZ8BjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def firebase_to_csv_counters(ref_path, output_file):\n",
        "#     ref = db.reference(ref_path)\n",
        "#     data = ref.get()\n",
        "#     transformed_data = []\n",
        "#     for pid, value in data.items():\n",
        "#         pid = pid.lower()\n",
        "#         # Case 1: only numeric\n",
        "#         if isinstance(value, int):\n",
        "#             transformed_data.append({'pid': pid, 'screen_event_count': value})\n",
        "\n",
        "#         # Case 2: dictionary => selecting only value\n",
        "#         elif isinstance(value, dict):\n",
        "#             numeric_values = [v for v in value.values() if isinstance(v, int)]\n",
        "#             if numeric_values:\n",
        "#                 total = sum(numeric_values)\n",
        "#                 transformed_data.append({'pid': pid, 'screen_event_count': total})\n",
        "\n",
        "#     df = pd.DataFrame(transformed_data)\n",
        "#     df = df[['pid', 'screen_event_count']]\n",
        "#     df.to_csv(output_file, index=False)\n",
        "\n",
        "\n",
        "# firebase_to_csv_counters('/ringer_event_counters','ringer_event_counters.csv')\n",
        "# ringer_event_counters_data0 = pd.read_csv('/content/ringer_event_counters.csv')\n",
        "# print(ringer_event_counters_data0.head())\n",
        "\n",
        "# firebase_to_csv_counters('/screen_event_counters','screen_event_counters.csv')\n",
        "# screen_event_counters_data0 = pd.read_csv('/content/screen_event_counters.csv')\n",
        "# print(screen_event_counters_data0.head())\n",
        "\n",
        "# firebase_to_csv_counters('/settings_change_counters','settings_change_counters.csv')\n",
        "# settings_change_counters_data0 = pd.read_csv('/content/settings_change_counters.csv')\n",
        "# print(settings_change_counters_data0.head())"
      ],
      "metadata": {
        "id": "fk6_muXpjtZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paricipant management"
      ],
      "metadata": {
        "id": "G9C8L__e-2KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Progress check\n",
        "\n",
        "Which day is each participant on, the state of each survey and the tutorial: unavailable, available, or completed."
      ],
      "metadata": {
        "id": "5JLcrCLQ-5T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read in the meta data"
      ],
      "metadata": {
        "id": "QmxqmvZ7AwKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the data\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "survey_data = pd.read_csv(google_drive_data_path + '/survey_meta.csv')\n",
        "survey_data['submitDate'] = pd.to_datetime(survey_data['timestamp'].map(convert_unix_to_date))\n",
        "\n",
        "# Pivot the dataframe to create survey columns\n",
        "survey_meta_pivoted = survey_data.pivot(index=['pid','host'], columns='surveyID', values='submitDate')\n",
        "\n",
        "# Rename the columns\n",
        "survey_meta_pivoted.columns = ['survey' + str(col) for col in survey_meta_pivoted.columns]\n",
        "\n",
        "# Reset the index to make pid a column again\n",
        "survey_meta_pivoted = survey_meta_pivoted.reset_index()\n",
        "\n",
        "\n",
        "# Get today's date once\n",
        "ny_tz = pytz.timezone('America/New_York')\n",
        "today = pd.Timestamp.now(tz=ny_tz).normalize().date()\n",
        "\n",
        "# Fixed date operations\n",
        "survey_meta_pivoted['survey1'] = pd.to_datetime(survey_meta_pivoted['survey1']).dt.date\n",
        "survey_meta_pivoted['real_day_count'] = np.array([today - d for d in survey_meta_pivoted['survey1']], dtype='timedelta64[D]').astype(int) + 1\n",
        "\n",
        "def calculate_app_day_count(row):\n",
        "   required_columns = ['survey2', 'survey3', 'survey4']\n",
        "   row = row.reindex([*row.index, *required_columns]).fillna(pd.NA)\n",
        "\n",
        "   today = pd.Timestamp.now(tz=ny_tz)\n",
        "   s1 = pd.to_datetime(row['survey1']).tz_localize(ny_tz)\n",
        "   days_since_s1 = (today - s1).days + 1\n",
        "\n",
        "   if pd.notna(row['survey4']):\n",
        "       return 0\n",
        "   if pd.isna(row['survey2']):\n",
        "       return min(8, days_since_s1)\n",
        "\n",
        "   s2 = pd.to_datetime(row['survey2']).tz_localize(ny_tz)\n",
        "   delay1 = max(0, (s2 - s1).days - 7)\n",
        "\n",
        "   if pd.isna(row['survey3']):\n",
        "       return min(15, days_since_s1 - delay1)\n",
        "\n",
        "   s3 = pd.to_datetime(row['survey3']).tz_localize(ny_tz)\n",
        "   delay2_threshold = 8 if (s2 - s1).days == 6 else 7\n",
        "   delay2 = max(0, (s3 - s2).days - delay2_threshold)\n",
        "\n",
        "   return min(22, days_since_s1 - delay1 - delay2)\n",
        "\n",
        "\n",
        "print(\"The shape of the dataframe is: \", survey_meta_pivoted.shape)\n",
        "\n",
        "survey_meta_pivoted['app_day_count'] = survey_meta_pivoted.apply(calculate_app_day_count, axis=1)\n",
        "\n",
        "survey_meta_pivoted = (survey_meta_pivoted\n",
        "   .assign(pid=lambda x: x['pid'].str.upper())\n",
        "   .rename(columns={'pid': 'PID'}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amBOeEpGmmoJ",
        "outputId": "03233ebf-e62e-48d0-bbb7-15afe607003a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the dataframe is:  (22, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the email info and merge"
      ],
      "metadata": {
        "id": "SyBFn33BA8fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the cell below, make sure the Participants.xlsx is up to date."
      ],
      "metadata": {
        "id": "zq-IN9cCKjN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "participant_data = pd.read_excel(google_drive_data_path + '/Participants.xlsx')\n",
        "\n",
        "survey_meta_manager = pd.merge(survey_meta_pivoted, participant_data, on='PID', how='right')\n",
        "\n",
        "# Sort by survey1\n",
        "survey_meta_manager = survey_meta_manager.sort_values(by='survey1')\n",
        "\n",
        "# Drop the specified columns\n",
        "survey_meta_manager = survey_meta_manager.drop(columns=['host', 'real_day_count'], errors='ignore')"
      ],
      "metadata": {
        "id": "I-up9q11ojae"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check latest update"
      ],
      "metadata": {
        "id": "U7fQPjI-Bu31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and process screen data in one chain\n",
        "latest_times = (pd.read_csv(google_drive_data_path + '/screen_events.csv')\n",
        "   .groupby('pid')['endTime']\n",
        "   .max()\n",
        "   .reset_index()\n",
        "   .assign(lastUpdate=lambda x: x['endTime'].map(lambda y: convert_unix_to_date(y, return_date=False)))\n",
        "   .drop(columns=['endTime'])\n",
        "   .assign(PID=lambda x: x['pid'].str.upper())\n",
        "   .drop(columns=['pid']))\n",
        "\n",
        "# Read and process timezone data in one chain\n",
        "timezone_data = (pd.read_csv(google_drive_data_path + '/timezones.csv')\n",
        "   .assign(PID=lambda x: x['pid'].str.upper())\n",
        "   .drop(columns=['pid'])\n",
        "   [['PID', 'timezone']])\n",
        "\n",
        "# Combine all merges and data cleaning in one chain\n",
        "survey_meta_manager = (survey_meta_manager\n",
        "   .merge(latest_times, on='PID', how='left')\n",
        "   .merge(timezone_data, on='PID', how='left')\n",
        "   .assign(lastUpdate=lambda x: x['lastUpdate'].astype(str).replace('NaT', ''))\n",
        "   .fillna(''))"
      ],
      "metadata": {
        "id": "4dYK9epYoxXn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update lastUpdate with Timezone"
      ],
      "metadata": {
        "id": "TrwVqrG6sqyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "def convert_to_local_time(row):\n",
        "    # Skip rows where either lastUpdate or timezone is missing\n",
        "    if pd.isna(row['lastUpdate']) or pd.isna(row['timezone']):\n",
        "        return pd.NaT\n",
        "\n",
        "    try:\n",
        "        # Parse the timestamp\n",
        "        dt = pd.to_datetime(row['lastUpdate'])\n",
        "        if pd.isna(dt):\n",
        "            return pd.NaT\n",
        "\n",
        "        # Get source timezone (EST/EDT)\n",
        "        source_tz = pytz.timezone('America/New_York')\n",
        "\n",
        "        # Localize the datetime\n",
        "        dt_source = source_tz.localize(dt.tz_localize(None))\n",
        "\n",
        "        # Convert to target timezone\n",
        "        target_tz = pytz.timezone(row['timezone'])\n",
        "        dt_target = dt_source.astimezone(target_tz)\n",
        "\n",
        "        return dt_target\n",
        "\n",
        "    except (ValueError, AttributeError):\n",
        "        return pd.NaT\n",
        "\n",
        "# Apply the conversion\n",
        "survey_meta_manager['local_time'] = survey_meta_manager.apply(convert_to_local_time, axis=1)\n",
        "\n",
        "# Replace \"NaT\" with empty strings in the 'lastUpdate' column\n",
        "survey_meta_manager['local_time'] = survey_meta_manager['local_time'].astype(str).replace('NaT', '')"
      ],
      "metadata": {
        "id": "qNxSDxWyuSx7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_time_lapse(last_update):\n",
        "    if pd.isna(last_update):\n",
        "        return None\n",
        "\n",
        "    # Get current time in EST (since lastUpdate is in EST)\n",
        "    est = pytz.timezone('America/New_York')\n",
        "    now = datetime.now(est)\n",
        "\n",
        "    try:\n",
        "        # Parse lastUpdate with timezone info (-05:00 is already in the data)\n",
        "        last_update = pd.to_datetime(last_update, utc=True)\n",
        "        last_update = last_update.astimezone(est)\n",
        "\n",
        "        # Calculate time difference\n",
        "        time_diff = now - last_update\n",
        "\n",
        "        # Convert to hours and minutes\n",
        "        total_minutes = time_diff.total_seconds() / 60\n",
        "        hours = int(total_minutes // 60)\n",
        "        minutes = int(total_minutes % 60)\n",
        "\n",
        "        # Format as HH:MM\n",
        "        return f\"{hours:02d}:{minutes:02d}\"\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Calculate time lapse for each row\n",
        "survey_meta_manager['time_lapse'] = survey_meta_manager['lastUpdate'].apply(calculate_time_lapse)\n",
        "\n",
        "# prompt: Rename \"nick name\":\"nick_name\", \"timezone\":\"time_zone\", \"local_time\":\"last_update_local\",\"time_lapse\":\"lapse_last_update\"\n",
        "\n",
        "# Rename the columns\n",
        "survey_meta_manager = survey_meta_manager.rename(columns={\n",
        "    \"survey1\": \"start_date\",\n",
        "    \"nick name\": \"nick_name\",\n",
        "    \"timezone\": \"time_zone\",\n",
        "    \"local_time\": \"last_update_local\",\n",
        "    \"time_lapse\": \"lapse_last_update\"\n",
        "})\n",
        "\n",
        "# prompt: reorder the columns: PID, Email, nick_name, start_date, app_day_count, last_update_local, lapse_last_update\n",
        "\n",
        "# Reorder the columns\n",
        "new_column_order = ['PID', 'Email', 'nick_name', 'start_date', 'app_day_count', 'last_update_local', 'lapse_last_update']\n",
        "survey_meta_manager = survey_meta_manager[new_column_order]\n",
        "\n",
        "survey_meta_manager.to_csv(google_drive_data_path + '/survey_meta_manager.csv', index=False)"
      ],
      "metadata": {
        "id": "8IY8RuwnvuUr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a status"
      ],
      "metadata": {
        "id": "xtMfDvWSKA9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, time\n",
        "\n",
        "# Read the CSV\n",
        "df = pd.read_csv(google_drive_data_path + '/survey_meta_manager.csv')\n",
        "# saved_status = pd.read_excel(google_drive_data_path + '/status_saved.xlsx')\n",
        "# df = df.merge(saved_status, on='Email', how='left')\n",
        "\n",
        "# Initialize status column with \"not yet started\" ONLY where status < 4 or NaN\n",
        "mask_initial = (df['status'] < 4) | (df['status'].isna())\n",
        "df.loc[mask_initial, 'status'] = 1\n",
        "\n",
        "# Convert lapse_last_update to datetime.time objects where possible\n",
        "def convert_time(x):\n",
        "    try:\n",
        "        if pd.notna(x):\n",
        "            hours, minutes = map(int, x.split(':'))\n",
        "            return time(hours, minutes)\n",
        "    except:\n",
        "        return pd.NaT\n",
        "\n",
        "df['lapse_time'] = df['lapse_last_update'].apply(convert_time)\n",
        "\n",
        "# Set status based on conditions, but only where status < 4 or NaN\n",
        "cutoff_time = time(12, 0)\n",
        "mask_eligible = (df['status'] < 4) | (df['status'].isna())\n",
        "\n",
        "# 1. If lapse_last_update < 12:00, status = \"started\"\n",
        "mask_started = df['lapse_time'].apply(lambda x: pd.notna(x) and isinstance(x, time) and x < cutoff_time)\n",
        "df.loc[mask_eligible & mask_started, 'status'] = 2\n",
        "\n",
        "# 2. If start_date is not empty but lapse_last_update is empty or â‰¥ 12:00\n",
        "mask_tech_issue = (pd.notna(df['start_date'])) & (~mask_started)\n",
        "df.loc[mask_eligible & mask_tech_issue, 'status'] = 3\n",
        "\n",
        "# Drop the temporary lapse_time column\n",
        "df = df.drop('lapse_time', axis=1)\n",
        "df[['Email','status']].to_excel(google_drive_data_path + '/status_saved.xlsx', index=False)"
      ],
      "metadata": {
        "id": "1gFMpaBC7Lgb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create status-note mapping dictionary from the CSV data\n",
        "status_mapping = {\n",
        "    0: 'to invite',\n",
        "    1: 'invited',\n",
        "    2: 'started',\n",
        "    3: 'data paused',\n",
        "    4: 'completed',\n",
        "    5: 'dropped out',\n",
        "    9: 'tester'\n",
        "}\n",
        "\n",
        "# Delete 'note_yesterday' column if it exists\n",
        "if 'note_yesterday' in df.columns:\n",
        "    df = df.drop(columns=['note_yesterday'])\n",
        "\n",
        "# Rename 'note' column to 'note_yesterday' if it exists\n",
        "if 'note' in df.columns:\n",
        "    df = df.rename(columns={'note': 'note_yesterday'})\n",
        "\n",
        "# Create a new 'note' column and initialize it with NaN\n",
        "df['note'] = float('nan')\n",
        "\n",
        "# Update the new 'note' column using the status mapping\n",
        "df.loc[df['note'].isna(), 'note'] = df.loc[df['note'].isna(), 'status'].map(status_mapping)\n",
        "df.to_csv(google_drive_data_path + '/survey_meta_manager.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeoBjOndqJOa",
        "outputId": "58940f0a-5a03-4aa8-c9ae-3e8c9b7ff885"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-b26f8a6b0097>:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['data paused' 'started' 'started' 'dropped out' 'started' 'started'\n",
            " 'started' 'data paused' 'started' 'data paused' 'started' 'started'\n",
            " 'started' 'started' 'started' 'started' 'started' 'started' 'started'\n",
            " 'started' 'started' 'tester' 'tester' 'started' 'invited' 'invited'\n",
            " 'invited' 'invited' 'invited' 'invited' 'invited' 'invited' 'invited']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[df['note'].isna(), 'note'] = df.loc[df['note'].isna(), 'status'].map(status_mapping)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## further process"
      ],
      "metadata": {
        "id": "YPk3Nfw5x_Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read both CSVs\n",
        "signup_df = pd.read_csv(google_drive_data_path + '/signup_survey_data_processed_combined.csv')\n",
        "survey_meta_df = df[['Email', 'status']]  # Using the df we created earlier\n",
        "\n",
        "# Merge the dataframes\n",
        "signup_df = signup_df.merge(survey_meta_df, on='Email', how='left')\n",
        "\n",
        "# Replace values in Note column with status values where status is not null\n",
        "mask = pd.notna(signup_df['status'])\n",
        "signup_df.loc[mask, 'Note'] = signup_df.loc[mask, 'status']\n",
        "\n",
        "# Drop the status column since we don't need it anymore\n",
        "signup_df = signup_df.drop('status', axis=1)\n"
      ],
      "metadata": {
        "id": "zCIBANg7LbRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signup_df.to_csv(google_drive_data_path + '/signup_survey_data_with_note.csv', index=False)"
      ],
      "metadata": {
        "id": "xTi53jdWMu1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Participants from Janel CSV\n",
        "janel_df = pd.read_csv(google_drive_data_path + '/Participants from Janel.csv')\n",
        "\n",
        "# Merge with signup_df\n",
        "janel_df = janel_df.merge(signup_df[['Email', 'Note']],\n",
        "                         on='Email',\n",
        "                         how='left',\n",
        "                         suffixes=('_old', '_new'))\n",
        "\n",
        "# If Note_new exists, use it to replace Note_old\n",
        "mask = pd.notna(janel_df['Note_new'])\n",
        "janel_df.loc[mask, 'Note_old'] = janel_df.loc[mask, 'Note_new']\n",
        "\n",
        "# Clean up column names\n",
        "janel_df = janel_df.rename(columns={'Note_old': 'Note'})\n",
        "janel_df = janel_df.drop('Note_new', axis=1)\n",
        "\n",
        "print(janel_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z2a1l-2NPzY",
        "outputId": "8f134dd2-073b-4c79-9bb4-6c2cce1a0019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Name                          Email signed up?  \\\n",
            "0   America haileselassie   Ahaileselassie7459@gmail.com        yes   \n",
            "1           Barbara Stras          Barbstraskc@gmail.com    not yet   \n",
            "2           Brian Troesch          Brian_60629@yahoo.com        yes   \n",
            "3         Brittany Thomas            btmarie33@gmail.com        yes   \n",
            "4           David Seltzer                djsboca@aol.ocm        yes   \n",
            "5                 Hong Vu              hongvuh@gmail.com        yes   \n",
            "6               Art Smosh            ibbincome@gmail.com        yes   \n",
            "7             Juan Moreno         jimoreno2055@gmail.com        yes   \n",
            "8      Katherine Mitchell  katherinemitchell98@yahoo.com    not yet   \n",
            "9        Kelley Pasmanick      kelleypasmanick@gmail.com        yes   \n",
            "10       Kimberly Tippett           Ktippett05@nc.rr.com        yes   \n",
            "11            Lauren Rich        laurenjrich@outlook.com        yes   \n",
            "12             carl mapps            Mappscarl@gmail.com        yes   \n",
            "13            Mark Winger        mark_winger@hotmail.com        yes   \n",
            "14      Nicole Krivitskiy          nkaganovsky@gmail.com   yes, but   \n",
            "15             Noah Reeve      Noahsschool2018@gmail.com        yes   \n",
            "16        Amanda Fishbeck       Notquiterite73@gmail.com        yes   \n",
            "17             Roald Mark             Roald820@gmail.com        yes   \n",
            "18       Sadie Santa Cruz       Sadiesantacruz@gmail.com        yes   \n",
            "19      Daniel Santa Cruz        santanana2000@yahoo.com        yes   \n",
            "20            TRACY SIMMS             SIMMSMBA@GMAIL.COM   yes, but   \n",
            "21            Kim Gilbert              ssksg73@gmail.com        yes   \n",
            "22         Kelsey Storrer              yeslek000@aol.com        yes   \n",
            "23             Yuan Kuang             yk010181@yahoo.com        yes   \n",
            "\n",
            "                                                 Note  \n",
            "0                                          tech issue  \n",
            "1                                          travelling  \n",
            "2                                             started  \n",
            "3                               screen time no enough  \n",
            "4                                                 NaN  \n",
            "5                                             started  \n",
            "6                                     not yet started  \n",
            "7                                             started  \n",
            "8                                                 NaN  \n",
            "9                               screen time no enough  \n",
            "10                                            started  \n",
            "11                                                NaN  \n",
            "12                                            started  \n",
            "13                              screen time no enough  \n",
            "14  Four responses from exactly same location with...  \n",
            "15                                            started  \n",
            "16                                            started  \n",
            "17                                         tech issue  \n",
            "18                                            started  \n",
            "19                                            started  \n",
            "20  Reported as suspicious from Qualtrics. Signed-...  \n",
            "21                                            started  \n",
            "22                              screen time no enough  \n",
            "23                                            started  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "janel_df.to_csv(google_drive_data_path + '/Participants from Janel noted.csv', index=False)"
      ],
      "metadata": {
        "id": "IMzL1bs1NlAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate reminder mail list"
      ],
      "metadata": {
        "id": "yo3YdmPp0ZCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a list of emails for certain filter. Copy the output into bcc in gmail"
      ],
      "metadata": {
        "id": "5IFbMEHF_QTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Locate the corresponding email in the document [Emails](https://docs.google.com/document/d/1e5TZJ6ILpku8rVdO_ADUwI-lM8SCIh7xG95jrG73INY/edit?usp=sharing)"
      ],
      "metadata": {
        "id": "gLfObLMXLC6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_emails_by_day_count(day_count):\n",
        "    emails = survey_meta_manager[survey_meta_manager['app_day_count'] == day_count]['Email'].tolist()\n",
        "    if emails:\n",
        "        return ','.join(emails)\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "5Gnj-Ly8WvlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Week 1 completion"
      ],
      "metadata": {
        "id": "ojA0MPE20e-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter those day_count is 7\n",
        "emails = get_emails_by_day_count(7)\n",
        "print(emails)"
      ],
      "metadata": {
        "id": "Y4P-gZgi0pQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041b7e85-d06c-41d9-8cd0-f653bd54494f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Week 2 completion"
      ],
      "metadata": {
        "id": "QWnH2Zud0exL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter those day_count is 14\n",
        "emails = get_emails_by_day_count(14)\n",
        "print(emails)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIXdomrCXEFg",
        "outputId": "bdb9d8da-84f5-48ee-a7d6-47b0e1e04d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Week 3 completion"
      ],
      "metadata": {
        "id": "nrXxVuNI0ep5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter those day_count is 21\n",
        "emails = get_emails_by_day_count(21)\n",
        "print(emails)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Zx5vq2XEaB",
        "outputId": "fdc61519-b7de-49be-e01b-80dc3d52df5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Daily reminder"
      ],
      "metadata": {
        "id": "ZSKaRnMO0eUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if there is an available survey awaiting\n",
        "# Create four columns with initial 'unavailable' status\n",
        "survey_meta_manager['survey1_status'] = 'unavailable'\n",
        "survey_meta_manager['survey2_status'] = 'unavailable'\n",
        "survey_meta_manager['survey3_status'] = 'unavailable'\n",
        "survey_meta_manager['survey4_status'] = 'unavailable'\n",
        "\n",
        "# Update status to 'complete' if there's a date in the survey columns\n",
        "for i in range(1, 5):\n",
        "    survey_meta_manager[f'survey{i}_status'] = np.where(survey_meta_manager[f'survey{i}'].notna(), 'complete', survey_meta_manager[f'survey{i}_status'])\n",
        "\n",
        "# Update status to 'available' if survey is NA and day_count exceeds the threshold\n",
        "thresholds = [6, 13, 20]\n",
        "for i, col in enumerate(['survey2', 'survey3', 'survey4'], start=2):\n",
        "    survey_meta_manager[f'{col}_status'] = np.where(\n",
        "        (survey_meta_manager[col].isna()) & (survey_meta_manager['app_day_count'] > thresholds[i-2]),\n",
        "        'available',\n",
        "        survey_meta_manager[f'{col}_status']\n",
        "    )\n",
        "\n",
        "# Save the updated DataFrame\n",
        "print(\"The shape of the dataframe is: \", survey_meta_manager.shape)\n",
        "survey_meta_manager.to_csv(google_drive_data_path + '/survey_meta_manager.csv', index=False)"
      ],
      "metadata": {
        "id": "zXvFdjmwdPli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83991d69-cc94-4e80-e82f-0fa0567ea984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the dataframe is:  (8, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get emails for participants with at least one 'available' survey\n",
        "target_participants = survey_meta_manager[(survey_meta_manager['survey2_status'] == 'available') |\n",
        "                                          (survey_meta_manager['survey3_status'] == 'available') |\n",
        "                                          (survey_meta_manager['survey4_status'] == 'available')]\n",
        "email_list = target_participants['email'].tolist()\n",
        "print(','.join(email_list) or 'None')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-uTbyU8dZT6",
        "outputId": "79126749-9281-4051-be07-f88206b816f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pi005@gmail.com,pi011@gmail.com,pi012@gmail.com,te010@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop out notification"
      ],
      "metadata": {
        "id": "jRTSFjyIM5F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If a survey is unanswered for seven days, send out a drop-out notification"
      ],
      "metadata": {
        "id": "a86pWV1cNFbZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}